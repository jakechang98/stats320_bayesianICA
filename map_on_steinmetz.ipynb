{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsEk5dm7yBVL"
      },
      "source": [
        "# MAP on Steinmetz\n",
        "We run our algorithm on the Steinmetz dataset, with an anatomically inspired connectivity matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlbWH3YXyqjT"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwQxQT9qjN1M",
        "outputId": "5716b500-bfa6-44b0-a707-828a0fe17dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA1P5IuB3JOS",
        "outputId": "1f54e6bb-6d27-4756-a5d4-deb2e256cd19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.8.4-py3-none-any.whl (730 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.7/730.7 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pyro-ppl) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.9/dist-packages (from pyro-ppl) (4.65.0)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.9/dist-packages (from pyro-ppl) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pyro-ppl) (4.5.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.8.4\n"
          ]
        }
      ],
      "source": [
        "pip install pyro-ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKbqa7SjyUQw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.auto import trange\n",
        "\n",
        "from scipy.spatial import distance\n",
        "from scipy.stats import pearsonr \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.distributions.laplace import Laplace\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions.dirichlet import Dirichlet\n",
        "from torch.distributions.gamma import Gamma\n",
        "from torch.distributions.exponential import Exponential\n",
        "from torch.distributions.bernoulli import Bernoulli\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.infer import MCMC, NUTS, HMC\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    \"\"\"Sets the seed for generating random numbers in PyTorch, numpy and\n",
        "    Python.\n",
        "\n",
        "    Args:\n",
        "        seed (int): The desired seed.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4iMxf9GzOS7"
      },
      "outputs": [],
      "source": [
        "def nx_to_laplacian(g, alpha=0.5):\n",
        "  \"\"\"\n",
        "  alpha: float, controls how much we augment the diagonal of the graph Laplacian\n",
        "  \"\"\"\n",
        "  adj_matrix = nx.convert_matrix.to_numpy_array(g)\n",
        "  deg = np.sum(adj_matrix, axis=1)\n",
        "  lap = np.diag(alpha + deg) - adj_matrix\n",
        "  return torch.from_numpy(lap).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grdHvNJWC2Lo"
      },
      "outputs": [],
      "source": [
        "def initialize_model(K, N, T, g, sigma=0.01, random_seed=0, mask=True, alpha=0.5):\n",
        "  \"\"\"\n",
        "  This function initializes our starting point for MAP estimation on L, D, A\n",
        "\n",
        "  K : number of factors\n",
        "  N: number of neurons\n",
        "  T: number of time steps\n",
        "  g: the base graph (with N neurons)\n",
        "  \"\"\"\n",
        "  seed_everything(random_seed)\n",
        "  S = Laplace(0, 1/np.sqrt(2 * T)).sample(sample_shape=(T,K)) # T x k\n",
        "  D = torch.sqrt(Dirichlet(torch.ones(K) / K).sample(sample_shape=(N,)).T)\n",
        "  A = torch.abs(MultivariateNormal(torch.zeros(N),  precision_matrix=nx_to_laplacian(g, alpha=alpha)).sample(sample_shape=(K, ))) #k x N\n",
        "\n",
        "  # let's make the Lambdas\n",
        "  B = Bernoulli(0.8).sample(sample_shape=(K,))\n",
        "  L = B * Gamma(10,10).sample(sample_shape=(K,))\n",
        "  E = (1 - B) * Exponential(1).sample(sample_shape=(K,))\n",
        "  L = L + E\n",
        "  L = L.sort().values\n",
        "\n",
        "  if mask:\n",
        "    Atilde = torch.diag(L) @ (D * A)\n",
        "  else:\n",
        "    Atilde = torch.diag(L) @ A\n",
        "\n",
        "  Y = Normal(S @ Atilde, sigma).sample() # T x N\n",
        "\n",
        "  return (S,A,D,L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWNZTNleLQPK"
      },
      "outputs": [],
      "source": [
        "def stable_softmax(x):\n",
        "    \"\"\"\n",
        "    Computes the numerically stable softmax of a tensor x on the first dimension.\n",
        "    \"\"\"\n",
        "    max_val, _ = torch.max(x, dim=0, keepdim=True)\n",
        "    x_exp = torch.exp(x - max_val)\n",
        "    x_sum = torch.sum(x_exp, dim=0, keepdim=True)\n",
        "    return x_exp / x_sum\n",
        "def stable_dirichlet(logit_D):\n",
        "    return logit_D.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfEHAPHqDvJF"
      },
      "outputs": [],
      "source": [
        "# compute losses\n",
        "# the problem is the log density of the Dirichlet\n",
        "\n",
        "def get_loss(Y, S, log_A, logit_D, log_L, g, sigma=0.01, alpha=0.5, beta=0, mask=True):\n",
        "  T, N = Y.shape\n",
        "  K, _ = log_A.shape\n",
        "  A = torch.exp(log_A)\n",
        "  L = torch.exp(log_L)\n",
        "  if mask:\n",
        "    D = torch.sqrt(stable_softmax(logit_D.T).T)  # D_i^2 is Dirichlet\n",
        "\n",
        "  loss = 0\n",
        "  # priors\n",
        "  loss += -Laplace(0, 1/np.sqrt(2 * T)).log_prob(S).sum()\n",
        "  loss += -MultivariateNormal(torch.zeros(N), precision_matrix=nx_to_laplacian(g, alpha=alpha)).log_prob(A).sum()\n",
        "  if mask:\n",
        "    loss += stable_dirichlet(logit_D)\n",
        "  \n",
        "  # Lambda loss\n",
        "  gam = torch.log(torch.tensor(0.8)) + Gamma(10,10).log_prob(L)\n",
        "  exp = torch.log(torch.tensor(0.2)) + Exponential(1).log_prob(L)\n",
        "  cat = torch.vstack([gam, exp])\n",
        "  loss += -torch.logsumexp(cat, 0).sum()\n",
        "\n",
        "\n",
        "  # likelihood\n",
        "  if mask:\n",
        "    Atilde = A * D\n",
        "    if D.isnan().sum() > 0:\n",
        "      print(\"D is nan\")\n",
        "      print(D)\n",
        "  else:\n",
        "    Atilde = A\n",
        "  loss += -Normal(S @ torch.diag(L) @ Atilde, sigma).log_prob(Y).sum()\n",
        "  # l1 regularization\n",
        "  loss += beta * torch.linalg.norm(A)\n",
        "  return loss / T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCtXPqgVFkOo"
      },
      "outputs": [],
      "source": [
        "def map_estimation(Y,\n",
        "                   g,\n",
        "                   K, \n",
        "                   N,\n",
        "                   num_steps=2000,\n",
        "                   alpha=0.5,\n",
        "                   beta=0,\n",
        "                   mask=False,\n",
        "                   random_seed=1,\n",
        "                   tol_steps=200):\n",
        "  pbar = trange(num_steps)\n",
        "  pbar.set_description(\"---\")\n",
        "  T, N = Y.shape\n",
        "  # intialization\n",
        "  S, A, D, L = initialize_model(K, N, T, g, random_seed=random_seed, mask=mask, alpha=alpha)\n",
        "  S = nn.parameter.Parameter(S)\n",
        "  log_A = nn.parameter.Parameter(torch.log(A))\n",
        "  logit_D = nn.parameter.Parameter(2 * torch.log(D)) #D_i^2 ~ Dirichlet\n",
        "  log_L = nn.parameter.Parameter(torch.log(L))\n",
        "\n",
        "  S_best = S\n",
        "  log_A_best = log_A\n",
        "  logit_D_best = logit_D\n",
        "  log_L_best = log_L\n",
        "  s = 0\n",
        "\n",
        "  best_loss = float('inf')\n",
        "  optimizer = optim.Adam([S,log_A, logit_D, log_L], lr=1e-1)\n",
        "  train_losses = []\n",
        "  for step in pbar:\n",
        "    if step-s > tol_steps:\n",
        "      print(s)\n",
        "      break\n",
        "    with torch.set_grad_enabled(True):\n",
        "        optimizer.zero_grad()\n",
        "        loss = get_loss(Y, S, log_A, logit_D, log_L, g, beta=beta, mask=mask)\n",
        "        if loss < best_loss:\n",
        "          s = step\n",
        "          log_L_best = log_L.detach().clone()\n",
        "          sort = log_L_best.sort()\n",
        "          log_L_best = sort.values\n",
        "          idxs = sort.indices\n",
        "\n",
        "          S_best = S.detach().clone()\n",
        "          S_best = S_best[:, idxs]\n",
        "\n",
        "          log_A_best = log_A.detach().clone()\n",
        "          log_A_best = log_A_best[idxs, :]\n",
        "\n",
        "          logit_D_best = logit_D.detach().clone()\n",
        "          logit_D_best = logit_D_best[idxs, :]\n",
        "\n",
        "          best_loss = loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.detach().numpy())\n",
        "\n",
        "  return S_best, torch.exp(log_A_best), torch.sqrt(stable_softmax(logit_D_best)), torch.exp(log_L_best), train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A6YpKLxhIoq"
      },
      "source": [
        "## Application Steinmetz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmlZZMoXpY9f"
      },
      "source": [
        "### load in Steinmetz data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E43IX7aD0CFo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from sklearn.decomposition import PCA\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXKub8S7-l1T"
      },
      "outputs": [],
      "source": [
        "# @title Figure settings\n",
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] = 15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DFMpPsI9g4x"
      },
      "outputs": [],
      "source": [
        "# @title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "313S3yxR9jR9"
      },
      "outputs": [],
      "source": [
        "# @title Data loading\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat,\n",
        "                      np.load('steinmetz_part%d.npz'%j,\n",
        "                              allow_pickle=True)['dat']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJYpIgb79lUP"
      },
      "outputs": [],
      "source": [
        "# Take a single mouse (the sample notebook takes mouse 11, since it has some neurons from vis_ctx)\n",
        "# The rest of this notebook will just focus on this mouse\n",
        "dat = alldat[11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0yQFJoKALaP"
      },
      "outputs": [],
      "source": [
        "def get_successful_trials(dat): \n",
        "  \"\"\"\n",
        "  Drop the trials where the mouse failed to correctly distinguish the contrast \n",
        "  identification challenge.\n",
        "\n",
        "  This returns the spike data on successful trials.\n",
        "\n",
        "  TODO: might want to wrap this into a whole data cleaning function that returns \n",
        "  the cleaned dat dictionary object instead of just spikes.\n",
        "  \"\"\"\n",
        "  result = np.zeros_like(dat[\"contrast_right\"])\n",
        "  mask1 = dat[\"contrast_right\"] > dat[\"contrast_left\"]\n",
        "  mask2 = dat[\"contrast_left\"] > dat[\"contrast_right\"]\n",
        "  result[mask1] = -1\n",
        "  result[mask2] = 1\n",
        "\n",
        "  success_idx = np.where(result == dat[\"response\"])\n",
        "  success_idx = np.squeeze(success_idx)\n",
        "\n",
        "  return dat[\"spks\"][:, success_idx, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwtX6w1aqnvx"
      },
      "outputs": [],
      "source": [
        "success_dat = get_successful_trials(dat)\n",
        "success_dat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEFfaaErpbd4"
      },
      "outputs": [],
      "source": [
        "steinmetz_adj = pd.read_csv(\"/content/drive/MyDrive/connectome_prior/steinmetz.csv\", dtype=int)\n",
        "\n",
        "G = nx.Graph(steinmetz_adj.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udefTh4krjAg"
      },
      "outputs": [],
      "source": [
        "Y = success_dat[:, 0, :]\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YztC4W83kVze"
      },
      "outputs": [],
      "source": [
        "MASK = False\n",
        "N = 698\n",
        "ALPHA = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnSbkzkdpEqS"
      },
      "outputs": [],
      "source": [
        "K = 10\n",
        "S1_map, A1_map, D1_map, L1_map, train1_losses = map_estimation(torch.tensor(Y.T), G, K, N, mask=MASK, num_steps=3000, alpha=ALPHA, tol_steps=300, random_seed=1)\n",
        "S2_map, A2_map, D2_map, L2_map, train2_losses = map_estimation(torch.tensor(Y.T), G, K, N, mask=MASK, num_steps=3000, alpha=ALPHA, tol_steps=300, random_seed=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7a7fQrJeiHw"
      },
      "outputs": [],
      "source": [
        "plt.plot(train1_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Adz1h9IeelnI"
      },
      "outputs": [],
      "source": [
        "plt.plot(train1_losses[-100:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS1rbPPupoxQ"
      },
      "outputs": [],
      "source": [
        "# sim = np.zeros((num_subgraphs,K))\n",
        "# for i in range(num_subgraphs):\n",
        "#   for j in range(K):\n",
        "#     if MASK:\n",
        "#       sim[i,j] = pearsonr( L1_map[j] * D1_map[j] * A1_map[j], L2_map[j] * D2_map[j] * A2_map[j])[0]\n",
        "#     else:\n",
        "#       sim[i,j] = pearsonr(L1_map[i] * A1[i], L2_map[j] * A2_map[j])[0]\n",
        "\n",
        "# plt.imshow(sim, vmin=0, vmax=1)\n",
        "# plt.colorbar()\n",
        "\n",
        "sim = np.zeros((K,K))\n",
        "for i in range(K):\n",
        "  for j in range(K):\n",
        "    if MASK:\n",
        "      sim[i,j] = pearsonr( L1_map[j] * D1_map[j] * A1_map[j], L2_map[j] * D2_map[j] * A2_map[j])[0]\n",
        "    else:\n",
        "      sim[i,j] = pearsonr(L1_map[i] * A1_map[i], L2_map[j] * A2_map[j])[0]\n",
        "\n",
        "plt.imshow(sim, vmin=0, vmax=1)\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urRv4oMxxnxJ"
      },
      "outputs": [],
      "source": [
        "L1_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-IcIj1y_f7D"
      },
      "outputs": [],
      "source": [
        "L2_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7pK5TY731SY"
      },
      "source": [
        "## MCMC for Steinmetz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0988FoBL3-v9"
      },
      "outputs": [],
      "source": [
        "N = 698\n",
        "K = 10\n",
        "Y=torch.tensor(Y.T)\n",
        "T,N=Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncscCjTw6CpA"
      },
      "outputs": [],
      "source": [
        "\n",
        "S_prior = dist.Laplace(0,1/np.sqrt(2 * T))\n",
        "A_prior = dist.MultivariateNormal(torch.zeros(N), precision_matrix=nx_to_laplacian(G))\n",
        "D_prior = dist.Dirichlet(torch.Tensor(K*[1/K]))\n",
        "L_prior = dist.Gamma(torch.Tensor([10.0]),torch.Tensor([10.0]))\n",
        "\n",
        "def model(data):\n",
        "  A = torch.zeros(K,N)\n",
        "  D = torch.zeros(K,N)\n",
        "  S = torch.zeros(T,K)\n",
        "  Lambda = torch.zeros(K)\n",
        "  for k in range(K):\n",
        "    A[k,:] = torch.abs(pyro.sample(f'A_tilde_prior_{k}', A_prior))\n",
        "    #Lambda[k] = pyro.sample(f'L_prior_{k}',L_prior)\n",
        "    for t in range(T):\n",
        "      S[t,k] = pyro.sample(f'S_prior_{t}_{k}',S_prior)\n",
        "  #for i in range(N):\n",
        "  #  D[:,i] = torch.sqrt(pyro.sample(f'D_prior_{i}',D_prior))\n",
        "  #Lambda,_ = torch.sort(Lambda)\n",
        "  #A = Lambda.unsqueeze(1)*A*D\n",
        "  #sigma_2 = 1/pyro.sample(\"Sigma_prior\",dist.Gamma(torch.Tensor([1.0]),torch.Tensor([1.0])))\n",
        "  with pyro.plate(\"data\", len(data)):\n",
        "        pyro.sample(\"obs\", dist.MultivariateNormal(S@A, 0.01*torch.eye(N)), obs=data)\n",
        "  \n",
        "pyro.clear_param_store()\n",
        "\n",
        "# 2. Define the MCMC kernel function we will employ, and tell\n",
        "# it to use the model function we defined as the basis for\n",
        "# sampling\n",
        "my_kernel = NUTS(model)\n",
        "\n",
        "\n",
        "# 3. Define the MCMC algorithm with our specific\n",
        "# implementation of choice and the number of samples\n",
        "# to use to evaluate the most likely distribution\n",
        "# of \"weight1\".\n",
        "\n",
        "my_mcmc = MCMC(my_kernel,\n",
        "               num_samples=100,\n",
        "               warmup_steps=50)\n",
        "\n",
        "# 4. Run the algorithm, send our observations \n",
        "# (notice this is the parameter model(observations) receives)\n",
        "mc_results=my_mcmc.run(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6oU9Nbq-aOm"
      },
      "outputs": [],
      "source": [
        "samples=torch.abs(my_mcmc.get_samples()[\"A_tilde_prior_0\"])\n",
        "samples.shape \n",
        "plt.acorr(samples[:,1].flatten().cpu(),maxlags = 299)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoDZjDYq-iN1"
      },
      "outputs": [],
      "source": [
        "Lambda = torch.zeros(K)\n",
        "A_sample = torch.zeros(K,N)\n",
        "D = torch.zeros(K,N)\n",
        "for k in range(K):\n",
        "    A_sample[k,:] = torch.abs(my_mcmc.get_samples()[f'A_tilde_prior_{k}']).mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIe6fnH0-p9m"
      },
      "outputs": [],
      "source": [
        "plt.imshow(A_sample.cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnFSC0W5-s_W"
      },
      "outputs": [],
      "source": [
        "num_subgraphs=K\n",
        "sim=np.zeros((num_subgraphs,num_subgraphs))\n",
        "for i in range(num_subgraphs):\n",
        "  for j in range(num_subgraphs):\n",
        "    sim[i,j]=pearsonr(A1.cpu()[i], A_sample.cpu()[j])[0]\n",
        "plt.imshow(sim,vmin=0,vmax=1)\n",
        "plt.colorbar()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
